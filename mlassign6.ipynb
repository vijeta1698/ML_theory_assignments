{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. In the sense of machine learning, what is a model? What is the best way to train a model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model represents what was learned by a machine learning algorithm. The model is the “thing” that is saved after running a machine learning algorithm on training data and represents the rules, numbers, and any other algorithm-specific data structures required to make predictions.29-Apr-2020\n",
    "<br>\n",
    "<b>Step 1: Begin with existing data<br></b>\n",
    "Machine learning requires us to have existing data—not the data our application will use when we run it, but data to learn from. You need a lot of real data, in fact, the more the better. The more examples you provide, the better the computer should be able to learn. So just collect every scrap of data you have and dump it and voila! Right? \n",
    "\n",
    "Wrong. In order to train the computer to understand what we want and what we don’t want, you need to prepare, clean and label your data. Get rid of garbage entries, missing pieces of information, anything that’s ambiguous or confusing. Filter your dataset down to only the information you’re interested in right now. Without high quality data, machine learning does not work. So take your time and pay attention to detail.\n",
    "\n",
    "<b>Step 2: Analyze data to identify patterns<br></b>\n",
    "Unlike conventional software development where humans are responsible for interpreting large data sets, with machine learning, you apply a machine learning algorithm to the data. But don’t think you’re off the hook. Choosing the right algorithm, applying it, configuring it and testing it is where the human element comes back in.    \n",
    "\n",
    "There are several platforms to choose from both commercial and open source. Explore solutions from Microsoft, Google, Amazon, IBM or open source frameworks like TensorFlow, Torch and Caffe. They each have their own strengths and downsides, and each will interpret the same dataset a different way. Some are faster to train. Some are more configurable. Some allow for more visibility into the decision process. In order to make the right choice, you need to experiment with a few algorithms and test until you find the one that gives you the results most aligned to what you’re trying to achieve with your data. \n",
    "\n",
    "When it’s all said and done, and you’ve successfully applied a machine learning algorithm to analyze your data and learn from it, you have a trained model.\n",
    "\n",
    "<b>Step 3: Make predictions<br></b>\n",
    "There is so much you can do with your newly trained model. You could import it into a software application you’re building, deploy it into a web back end or upload and host it into a cloud service. Your trained model is now ready to take in new data and feed you predictions, aka results. \n",
    "\n",
    "These results can look different depending on what kind of algorithm you go with. If you need to know what something is, go with a classification algorithm, which comes in two types. Binary classification categorizes data between two categories. Multi-class classification sorts data between—you guessed it—multiple categories. \n",
    "\n",
    "When the result you’re looking for is an actual number, you’ll want to use a regression algorithm. Regression takes a lot of different data with different weights of importance and analyzes it with historical data to objectively provide an end result. \n",
    "\n",
    "Both regression and classification are supervised types of algorithms, meaning you need to provide intentional data and direction for the computer to learn. There is also unsupervised algorithms which don’t require labeled data or any guidance on the kind of result you’re looking for. \n",
    "\n",
    "One form of unsupervised algorithms is clustering. You use clustering when you want to understand the structure of your data. You provide a set of data and let the algorithm identify the categories within that set. On the other hand, anomaly is an unsupervised algorithm you can use when your data looks normal and uniform, and you want the algorithm to pull anything out of the ordinary that doesn’t fit with the rest of the data. \n",
    "\n",
    "Although supervised algorithms are more common, it’s good to play around with each algorithm type and use case to better understand probability and practice splitting and training data in different ways. The more you toy with your data, the better your understanding of what machine learning can accomplish will become. \n",
    "\n",
    "Ultimately, machine learning helps you find new ways to make life easier for your customers and easier for yourself. Self-driving cars not necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. In the sense of machine learning, explain the &quot;No Free Lunch&quot; theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The No Free Lunch Theorem is often thrown around in the field of optimization and machine learning, often with little understanding of what it means or implies.\n",
    "\n",
    "The theorem states that all optimization algorithms perform equally well when their performance is averaged across all possible problems.\n",
    "\n",
    "It implies that there is no single best optimization algorithm. Because of the close relationship between optimization, search, and machine learning, it also implies that there is no single best machine learning algorithm for predictive modeling problems such as classification and regression.\n",
    "\n",
    "In this tutorial, you will discover the no free lunch theorem for optimization and search.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "The no free lunch theorem suggests the performance of all optimization algorithms are identical, under some specific constraints.\n",
    "There is provably no single best optimization algorithm or machine learning algorithm.\n",
    "The practical implications of the theorem may be limited given we are interested in a small subset of all possible objective functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Describe the K-fold cross-validation mechanism in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Fold Cross-Validation\n",
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "\n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.\n",
    "\n",
    "Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.\n",
    "\n",
    "It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.\n",
    "\n",
    "The general procedure is as follows:\n",
    "\n",
    "Shuffle the dataset randomly.\n",
    "Split the dataset into k groups\n",
    "For each unique group:\n",
    "Take the group as a hold out or test data set\n",
    "Take the remaining groups as a training data set\n",
    "Fit a model on the training set and evaluate it on the test set\n",
    "Retain the evaluation score and discard the model\n",
    "Summarize the skill of the model using the sample of model evaluation scores\n",
    "Importantly, each observation in the data sample is assigned to an individual group and stays in that group for the duration of the procedure. This means that each sample is given the opportunity to be used in the hold out set 1 time and used to train the model k-1 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Describe the bootstrap sampling method. What is the aim of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrap method is a resampling technique used to estimate statistics on a population by sampling a dataset with replacement.\n",
    "\n",
    "It can be used to estimate summary statistics such as the mean or standard deviation. It is used in applied machine learning to estimate the skill of machine learning models when making predictions on data not included in the training data.\n",
    "\n",
    "A desirable property of the results from estimating machine learning model skill is that the estimated skill can be presented with confidence intervals, a feature not readily available with other methods such as cross-validation.\n",
    "\n",
    "In this tutorial, you will discover the bootstrap resampling method for estimating the skill of machine learning models on unseen data.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "The bootstrap method involves iteratively resampling a dataset with replacement.\n",
    "That when using the bootstrap you must choose the size of the sample and the number of repeats.\n",
    "The scikit-learn provides a function that you can use to resample a dataset for the bootstrap method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ensemble methods is a machine learning technique that combines several base models in order to produce one optimal predictive model. To better understand this definition lets take a step back into ultimate goal of machine learning and model building. This is going to make more sense as I dive into specific examples and why Ensemble methods are used.\n",
    "I will largely utilize Decision Trees to outline the definition and practicality of Ensemble Methods (however it is important to note that Ensemble Methods do not only pertain to Decision Trees).<br>\n",
    "<b>Types of Ensemble Methods</b><br>\n",
    "BAGGing, or Bootstrap AGGregating. BAGGing gets its name because it combines Bootstrapping and Aggregation to form one ensemble model. Given a sample of data, multiple bootstrapped subsamples are pulled. A Decision Tree is formed on each of the bootstrapped subsamples. After each subsample Decision Tree has been formed, an algorithm is used to aggregate over the Decision Trees to form the most efficient predictor.\n",
    "<br>\n",
    "2. Random Forest Models. Random Forest Models can be thought of as BAGGing, with a slight tweak. When deciding where to split and how to make decisions, BAGGed Decision Trees have the full disposal of features to choose from. Therefore, although the bootstrapped samples may be slightly different, the data is largely going to break off at the same features throughout each model. In contrary, Random Forest models decide where to split based on a random selection of features. Rather than splitting at similar features at each node throughout, Random Forest models implement a level of differentiation because each tree will split based on different features. This level of differentiation provides a greater ensemble to aggregate over, ergo producing a more accurate predictor<br>\n",
    "\n",
    "\n",
    "The goal of any machine learning problem is to find a single model that will best predict our wanted outcome. Rather than making one model and hoping this model is the best/most accurate predictor we can make, ensemble methods take a myriad of models into account, and average those models to produce one final model. It is important to note that Decision Trees are not the only form of ensemble methods, just the most popular and relevant in DataScience today./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. What is a descriptive model&#39;s main purpose? Give examples of real-world problems thatdescriptive models were used to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A descriptive model describes the domain it represents in a manner that can be interpreted by humans as well as computers. It can be used for many purposes, such as those described in Chapter 2, Section 2.2.2. It can include behavioral, structural, and other descriptions that establish logical relationships about the system, such as its whole-part relationship, the interconnection between its parts, and the allocation of its behavioral elements to structural elements. Descriptive models are generally not built in a manner that directly supports simulation, animation or execution, but they can be checked for consistency and adherence to the rules of the language, and the logical relationships can be reasoned about.\n",
    "\n",
    "The system model is a descriptive model that captures the requirements, structure, behavior, and parametric constraints associated with a system and its environment. The system model also captures inter-relationships between elements that represent its requirements, structure, behavior and parametric constraints. Because its modeling language supports various abstraction techniques, the system model also provides the ability to represent many other views of the system, such as a black-box view, white-box view, or a security view of the system. The system model can also be queried and analyzed for consistency, and serves as an integrating framework<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Describe how to evaluate a linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE)<br>\n",
    "The most common metric for regression tasks is MSE. It has a convex shape. It is the average of the squared difference between the predicted and actual value. Since it is differentiable and has a convex shape, it is easier to optimize.\n",
    "\n",
    "Mean squared error. Image by the author.\n",
    "MSE penalizes large errors.\n",
    "Mean Absolute Error (MAE)\n",
    "This is simply the average of the absolute difference between the target value and the value predicted by the model. Not preferred in cases where outliers are prominent.\n",
    "\n",
    "Mean absolute error. \n",
    "MAE does not penalize large errors.\n",
    "R-squared or Coefficient of Determination\n",
    "This metric represents the part of the variance of the dependent variable explained by the independent variables of the model. It measures the strength of the relationship between your model and the dependent variable.\n",
    "To understand what R-square really represents let us consider the following case where we measure the error of the model with and without the knowledge of the independent variables.\n",
    "Calculating regression error\n",
    "When we know the values of the independent variables, we can calculate the regression error.\n",
    "We know that residual is the difference between actual and predicted value. Thus, RSS (Residual sum of squares) can be calculated as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "9. Distinguish :\n",
    "\n",
    "1. Descriptive vs. predictive models\n",
    "\n",
    "2. Underfitting vs. overfitting the model\n",
    "\n",
    "3. Bootstrapping vs. cross-validation\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Descriptive vs. predictive models\n",
    "</b><br>\n",
    "\n",
    "Descriptive data mining\tPredictive data mining\n",
    "Descriptive mining is usually used to provide correlation, cross-tabulation, frequency, etc.\tThe term 'Predictive' means to predict something, so predictive data mining is the analysis done to predict the future event or other data or trends.\n",
    "It is based on the reactive approach.\tIt is based on the proactive approach.\n",
    "It specifies the characteristics of the data in a target data set.\tIt executes the induction over the current and past data so that prediction can happen.\n",
    "It needs data aggregation and data mining.\tIt needs statistics and data forecasting procedures.\n",
    "It provides precise data.\tIt produces outcomes without ensuring accuracy.\n",
    "\n",
    "<b>2. Underfitting vs. overfitting the model\n",
    "</b></br>\n",
    "Your model is underfitting the training data when the model performs poorly on the training data. This is because the model is unable to capture the relationship between the input examples (often called X) and the target values (often called Y). Your model is overfitting your training data when you see that the model performs well on the training data but does not perform well on the evaluation data. This is because the model is memorizing the data it has seen and is unable to generalize to unseen examples.\n",
    "<b>3. Bootstrapping vs. cross-validation\n",
    "</b>\n",
    "<br>\n",
    "6\n",
    "\n",
    "Bootstrapping is any test or metric that relies on random sampling with replacement.It is a method that helps in many situations like validation of a predictive model performance, ensemble methods, estimation of bias and variance of the parameter of a model etc. It works by performing sampling with replacement from the original dataset, and at the same time assuming that the data points that have not been choses are the test dataset. We can repeat this procedure several times and compute the average score as estimation of our model performance. Also, Bootstrapping is related to the ensemble training methods, because we can build a model using each bootstrap datasets and “bag” these models in an ensemble using the majority voting (for classification) or computing the average (for numerical predictions) for all of these models as our final result.\n",
    "\n",
    "Cross validation is a procedure for validating a model's performance, and it is done by splitting the training data into k parts. We assume that the k-1 parts is the training set and use the other part is our test set. We can repeat that k times differently holding out a different part of the data every time. Finally, we take the average of the k scores as our performance estimation. Cross validation can suffer from bias or variance. Increasing the number of splits, the variance will increase too and the bias will decrease. On the other hand, if we decrease the number of splits, the bias will increase and the variance will decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "10. Make quick notes on:\n",
    "\n",
    "1. LOOCV.\n",
    "\n",
    "2. F-measurement\n",
    "\n",
    "3. The width of the silhouette\n",
    "\n",
    "4. Receiver operating characteristic curve\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1</b><br>\n",
    "The Leave-One-Out Cross-Validation, or LOOCV, procedure is used to estimate the performance of machine learning algorithms when they are used to make predictions on data not used to train the model.\n",
    "\n",
    "It is a computationally expensive procedure to perform, although it results in a reliable and unbiased estimate of model performance. Although simple to use and no configuration to specify, there are times when the procedure should not be used, such as when you have a very large dataset or a computationally expensive model to evaluate.\n",
    "\n",
    "The leave-one-out cross-validation procedure is appropriate when you have a small dataset or when an accurate estimate of model performance is more important than the computational cost of the method.\n",
    "How to use the scikit-learn machine learning library to perform the leave-one-out cross-validation procedure.\n",
    "How to evaluate machine learning algorithms for classification and regression using leave-one-out cross-validation.\n",
    "<b>2</b><br>\n",
    "Assume an information retrieval (IR) system has recall R and precision P on a test document collection and an information need. The F-measure of the system is defined as the weighted harmonic mean of its precision and recall, that is,   F=1α1P+(1−α)1R\n",
    "<b>2</b><br>\n",
    "A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. The method was originally developed for operators of military radar receivers starting in 1941, which led to its name.\n",
    "\n",
    "The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate is also known as sensitivity, recall or probability of detection.[9] The false-positive rate is also known as probability of false alarm[9] and can be calculated as (1 − specificity). It can also be thought of as a plot of the power as a function of the Type I Error of the decision rule (when the performance is calculated from just a sample of the population, it can be thought of as estimators of these quantities). The ROC curve is thus the sensitivity or recall as a function of fall-out. In general, if the probability distributions for both detection and false alarm are known, the ROC curve can be generated by plotting the cumulative distribution function (area under the probability distribution from {\\displaystyle -\\infty }-\\infty  to the discrimination threshold) of the detection probability in the y-axis versus the cumulative distribution function of the false-alarm probability on the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
