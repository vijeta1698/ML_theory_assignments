{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c55702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. What is the definition of a target function? In the sense of a real-life example, express the target\n",
    "# function. How is a target function's fitness assessed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47a6a4e",
   "metadata": {},
   "source": [
    "<p>A target function, in machine learning, is a method for solving a problem that an AI algorithm parses its training data to find. Once an algorithm finds its target function, that function can be used to predict results (predictive analysis).The function can then be used to find output data related to inputs for real problems where, unlike training sets, outputs are not included.</p>\n",
    "<p>Analyzing the massive amounts of data related to its given problem, an AI derives understanding of previously unspecified rules by detecting consistencies in the data. The observations of inherent rules about how the studied subject operates inform the AI on how to process future data that does not include an output by applying this previously unknown function.</p>\n",
    "<p>The target function is essentially the formula that an algorithm feeds data to in order to calculate predictions. As in algebra, it is common when training AI to find the variable from the solution, working in reverse. The function as defined by f is applied to the input (I) to produce the output (I), Therefore O= f(I).</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4a02d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What are predictive models, and how do they work? What are descriptive types, and how do you\n",
    "# use them? Examples of both types of models should be provided. Distinguish between these two\n",
    "# forms of models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1901a684",
   "metadata": {},
   "source": [
    "<p>Predictive modeling is a statistical technique using machine learning and data mining to predict and forecast likely future outcomes with the aid of historical and existing data. It works by analyzing current and historical data and projecting what it learns on a model generated to forecast likely outcomes.</p>\n",
    "<p>A predictive model is not fixed; it is validated or revised regularly to incorporate changes in the underlying data. In other words, it’s not a one-and-done prediction. Predictive models make assumptions based on what has happened in the past and what is happening now. If incoming, new data shows changes in what is happening now, the impact on the likely future outcome must be recalculated, too. For example, a software company could model historical sales data against marketing expenditures across multiple regions to create a model for future revenue based on the impact of the marketing spend.</p>\n",
    "<p>Most predictive models work fast and often complete their calculations in real time. That’s why banks and retailers can, for example, calculate the risk of an online mortgage or credit card application and accept or decline the request almost instantly based on that prediction.</p>\n",
    "<p>Some predictive models are more complex, such as those used in computational biology and quantum computing; the resulting outputs take longer to compute than a credit card application but are done much more quickly than was possible in the past thanks to advances in technological capabilities, including computing power.</p>\n",
    "<br><p> A descriptive model is used for tasks that would benefit from the insight gained from summarizing data in new and interesting ways. As opposed to predictive models that predict a target of interest, in a descriptive model, no single feature is more important than any other. In fact, because there is no target to learn, the process of training a descriptive model is called unsupervised learning. Although it can be more difficult to think of applications for descriptive models, what good is a learner that isn't learning anything in particular - they are used quite regularly for data mining.</p>\n",
    "<p>So, in unsupervised learning algorithm, we do not have any target or outcome variable to predict / estimate. It is used for clustering population in different groups, which is widely used for segmenting customers in different groups for specific intervention. Examples of Unsupervised Learning: Apriori algorithm, K-means.</p>\n",
    "<p>For example, the descriptive modeling task called pattern discovery is used to identify useful associations within data. Pattern discovery is often used for market basket analysis on retailers' transactional purchase data. Here, the goal is to identify items that are frequently purchased together, such that the learned information can be used to refine marketing tactics. For instance, if a retailer learns that swimming trunks are commonly purchased at the same time as sunglasses, the retailer might reposition the items more closely in the store or run a promotion to \"up-sell\" customers on associated items.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0098dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Describe the method of assessing a classification model's efficiency in detail. Describe the various\n",
    "# measurement parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bc56b7",
   "metadata": {},
   "source": [
    "<p>Classification is a supervised learning approach in which a target variable is discrete (or categorical). Evaluating a machine learning model is as important as building it. We are creating models to perform on new, previously unseen data. Hence, a thorough and versatile evaluation is required to create a robust model. When it comes to classification models, evaluation process gets somewhat tricky.</p>\n",
    "<p><strong>accuracy = number of correct predictions / total number of predictions</strong></p>\n",
    "<p>So, if I had 100 people, 50 of whom were cheese lovers and 50 of who were cheese haters, and I correctly identified 36 of the cheese lovers and 24 of the cheese haters, my accuracy would be</p>\n",
    "<p><strong>accuracy = (36+24) / (50+50) = 60%.</strong></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd2c69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.\n",
    "# i. In the sense of machine learning models, what is underfitting? What is the most common\n",
    "# reason for underfitting?\n",
    "# ii. What does it mean to overfit? When is it going to happen?\n",
    "# iii. In the sense of model fitting, explain the bias-variance trade-off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9ba5e",
   "metadata": {},
   "source": [
    "<p><b>i</b>Underfitting is a scenario in data science where a data model is unable to capture the relationship between the input and output variables accurately, generating a high error rate on both the training set and unseen data.</p>\n",
    "<p>It occurs when a model is too simple, which can be a result of a model needing more training time, more input features, or less regularization.</p>\n",
    "<p>\n",
    "Overfitting refers to a model that models the training data too well.<br>\n",
    "\n",
    "Overfitting happens when a model learns the detail and noise in the training data to the extent that it negatively impacts the performance of the model on new data. This means that the noise or random fluctuations in the training data is picked up and learned as concepts by the model. The problem is that these concepts do not apply to new data and negatively impact the models ability to generalize.</p>\n",
    "<p>The bias–variance tradeoff is the property of a model that the variance of the parameter estimated across samples can be reduced by increasing the bias in the estimated parameters. The bias–variance dilemma or bias–variance problem is the conflict in trying to simultaneously minimize these two sources of error that prevent supervised learning algorithms from generalizing beyond their training set:\n",
    "<ul><li>\n",
    "The bias error is an error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).</li><li>\n",
    "The variance is an error from sensitivity to small fluctuations in the training set. High variance may result from an algorithm modeling the random noise in the training data (overfitting).</li></ul><p>\n",
    "The bias–variance decomposition is a way of analyzing a learning algorithm's expected generalization error with respect to a particular problem as a sum of three terms, the bias, variance, and a quantity called the irreducible error, resulting from noise in the problem itself.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625d7c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Is it possible to boost the efficiency of a learning model? If so, please clarify how."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999e6765",
   "metadata": {},
   "source": [
    "<p>Yes it is possible to boost the efficiency of a learning model :</p>\n",
    "<ul>\n",
    "    <li><strong>Using cross-validation correctly</strong><br>Seeing a large difference between the cross-validation (CV) estimates and the result is a common problem that appears with a test set or fresh data. Having this problem means that something went wrong with the cross-validation. Beyond the fact that CV isn’t a good performance predictor, this problem also means that a misleading indicator has induced you to model the problem incorrectly and achieve unsatisfactory results.</li>\n",
    "    <li><strong>Choosing the right error or score metric</strong><br>Trying to optimize an error metric based on the median error by using a learning algorithm based on the mean error won’t provide you with the best results unless you manage the optimization process in a fashion that works in favor of your chosen metric. When solving a problem using data and machine learning, you need to analyze the problem and determine the ideal metric to optimize.\n",
    "Examples can help a lot. You can get many of them from academic papers and from public machine learning contests that carefully define specific problems in terms of data and error/score metric. Look for a contest whose objective and data are similar to yours, and then check the requested metric.</li>\n",
    "    <li><strong>Searching for the best hyper-parameters</strong><br>Most algorithms perform fairly well out of the box using the default parameter settings. However, you can always achieve better results by testing different hyper-parameters. All you have to do is to create a grid search among possible values that your parameters can take and evaluate the results using the right error or score metric. The search takes time, but it can improve your results.</li>\n",
    "    <li><strong>Testing multiple models</strong><br>As a good practice, test multiple models, starting with the basic ones — the models that have more bias than variance. You should always favor simple solutions over complex ones. You may discover that a simple solution performs better.</li>\n",
    "    <li><strong>Averaging models</strong><br>Machine learning involves building many models and creating many different predictions, all with different expected error performances. It may surprise you to know that you can get even better results by averaging the models together. The principle is quite simple: Estimate variance is random, so by averaging many different models, you can enhance the signal and rule out the noise that will often cancel itself.</li>\n",
    "    <li><strong>Stacking models</strong><br>For the same reasons that averaging works, stacking can also provide you with better performance. In stacking, you build your machine learning models in two stages. Initially this technique predicts multiple results using different algorithms, with all of them learning from the features present in your data. During the second phase, instead of providing features that a new model will learn, you provide that model with the predictions of the other, previously trained models.\n",
    "Using a two-stage approach is justified when guessing complex target functions. You can approximate them only by using multiple models together and then by combining the result of the multiplication in a smart way. You can use a simple logistic regression or a complex tree ensemble as a second-stage model.</li>\n",
    "    <li><strong>Applying feature engineering</strong><br>If you believe that bias is still affecting your model, you have little choice but to create new features that improve the model’s performance. Every new feature can make guessing the target response easier.\n",
    "Automatic feature creation is possible using polynomial expansion or the support vector machines class of machine learning algorithms. Support vector machines can automatically look for better features in higher-dimensional feature spaces in a way that’s both computationally fast and memory optimal.\n",
    "\n",
    "However, nothing can really substitute for your expertise and understanding of the method needed to solve the data problem that the algorithm is trying to learn. You can create features based on your knowledge and ideas of how things work in the world. Humans are still unbeatable in doing so, and machines can’t easily replace them.</li>\n",
    "    <li><strong>Selecting features and examples</strong><br>If estimate variance is high and your algorithm is relying on many features, you need to prune some features for better results. In this context, reducing the number of features in your data matrix by picking those with the highest predictive value is advisable.\n",
    "When working with linear models, linear support vector machines, or neural networks, regularization is always an option. Both L1 and L2 can reduce the influence of redundant variables or even remove them from the model. Stability selection leverages the L1 ability to exclude less useful variables. The technique resamples the training data to confirm the exclusion.</li>\n",
    "    <li><strong>Looking for more data</strong><br>After trying all the previous suggestions, you may still have a high variance of predictions to deal with. In this case, your only option is to increase your training set size. Try increasing your sample by providing new data, which could translate into new cases or new features.\n",
    "If you want to add more cases, just look to see whether you have similar data at hand. If you want to add new features, locate an open source data source, if possible, to match your data with its entries. Another great way to obtain both new cases and new features is by scraping the data from the web. Often, data is available between different sources or through an application programming interface (API). For instance, Google APIs offer many geographical and business information sources.</li>\n",
    " \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c223bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. How would you rate an unsupervised learning model's success? What are the most common\n",
    "# success indicators for an unsupervised learning model ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11992bbc",
   "metadata": {},
   "source": [
    "accuracy check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d9cf9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Is it possible to use a classification model for numerical data or a regression model for categorical\n",
    "# data with a classification model? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a66604d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62e876a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Describe the predictive modeling method for numerical values. What distinguishes it from\n",
    "# categorical predictive modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7620743a",
   "metadata": {},
   "source": [
    "Predictive modeling is a statistical technique using machine learning and data mining to predict and forecast likely future outcomes with the aid of historical and existing data. It works by analyzing current and historical data and projecting what it learns on a model generated to forecast likely outcomes.<br>\n",
    "A predictive model is not fixed; it is validated or revised regularly to incorporate changes in the underlying data. In other words, it’s not a one-and-done prediction. Predictive models make assumptions based on what has happened in the past and what is happening now. If incoming, new data shows changes in what is happening now, the impact on the likely future outcome must be recalculated, too. For example, a software company could model historical sales data against marketing expenditures across multiple regions to create a model for future revenue based on the impact of the marketing spend.<br>\n",
    "Most predictive models work fast and often complete their calculations in real time. That’s why banks and retailers can, for example, calculate the risk of an online mortgage or credit card application and accept or decline the request almost instantly based on that prediction.<br>\n",
    "Some predictive models are more complex, such as those used in computational biology and quantum computing; the resulting outputs take longer to compute than a credit card application but are done much more quickly than was possible in the past thanks to advances in technological capabilities, including computing power.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f40bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. The following data were collected when using a classification model to predict the malignancy of a\n",
    "# group of patients tumors:\n",
    "# i. Accurate estimates – 15 cancerous, 75 benign\n",
    "# ii. Wrong predictions – 3 cancerous, 7 benign\n",
    "# Determine the model's error rate, Kappa value, sensitivity, precision, and F-measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f170fe",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2f6b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Make quick notes on:\n",
    "# 1. The process of holding out\n",
    "# 2. Cross-validation by tenfold\n",
    "# 3. Adjusting the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9dc6c",
   "metadata": {},
   "source": [
    "<p><b>Cross Validation By tenfold</b></p>\n",
    "<p>Cross-validation is a statistical method used to estimate the skill of machine learning models.</p>\n",
    "<p>It is commonly used in applied machine learning to compare and select a model for a given predictive modeling problem because it is easy to understand, easy to implement, and results in skill estimates that generally have a lower bias than other methods.</p>\n",
    "<p>k-Fold Cross-Validation</p>\n",
    "<p>Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.</p>\n",
    "<p>The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=10 becoming 10-fold cross-validation.</p>\n",
    "<p>Cross-validation is primarily used in applied machine learning to estimate the skill of a machine learning model on unseen data. That is, to use a limited sample in order to estimate how the model is expected to perform in general when used to make predictions on data not used during the training of the model.</p>\n",
    "<p>It is a popular method because it is simple to understand and because it generally results in a less biased or less optimistic estimate of the model skill than other methods, such as a simple train/test split.</p>\n",
    "<p>\n",
    "The general procedure is as follows:\n",
    "\n",
    "Shuffle the dataset randomly.<br>\n",
    "Split the dataset into k groups<br>\n",
    "For each unique group:<br>\n",
    "Take the group as a hold out or test data set<br>\n",
    "Take the remaining groups as a training data set<br>\n",
    "Fit a model on the training set and evaluate it on the test set<br>\n",
    "Retain the evaluation score and discard the model<br>\n",
    "Summarize the skill of the model using the sample of model evaluation scores\n",
    "</p>\n",
    "<p><b>Adjusting the parameters</b></p>\n",
    "<p>Hyperparameters contain the data that govern the training process itself.<br>\n",
    "\n",
    "Your training application handles three categories of data as it trains your model:\n",
    "<br>\n",
    "Your input data (also called training data) is a collection of individual records (instances) containing the features important to your machine learning problem. This data is used during training to configure your model to accurately make predictions about new instances of similar data. However, the values in your input data never directly become part of your model.\n",
    "<br>\n",
    "Your model's parameters are the variables that your chosen machine learning technique uses to adjust to your data. For example, a deep neural network (DNN) is composed of processing nodes (neurons), each with an operation performed on data as it travels through the network. When your DNN is trained, each node has a weight value that tells your model how much impact it has on the final prediction. Those weights are an example of your model's parameters. In many ways, your model's parameters are the model—they are what distinguishes your particular model from other models of the same type working on similar data.\n",
    "<br>\n",
    "Your hyperparameters are the variables that govern the training process itself. For example, part of setting up a deep neural network is deciding how many hidden layers of nodes to use between the input layer and the output layer, and how many nodes each layer should use. These variables are not directly related to the training data. They are configuration variables. Note that parameters change during a training job, while hyperparameters are usually constant during a job.\n",
    "<br>\n",
    "Your model parameters are optimized (you could say \"tuned\") by the training process: you run data through the operations of the model, compare the resulting prediction with the actual value for each data instance, evaluate the accuracy, and adjust until you find the best values. Hyperparameters are tuned by running your whole training job, looking at the aggregate accuracy, and adjusting. In both cases you are modifying the composition of your model in an effort to find the best combination to handle your problem.\n",
    "<br>\n",
    "Without an automated technology like AI Platform Training hyperparameter tuning, you need to make manual adjustments to the hyperparameters over the course of many training runs to arrive at the optimal values. Hyperparameter tuning makes the process of determining the best hyperparameter settings easier and less tedious.<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7a8e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Define the following terms:\n",
    "# 1. Purity vs. Silhouette width\n",
    "# 2. Boosting vs. Bagging\n",
    "# 3. The eager learner vs. the lazy learner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836cba80",
   "metadata": {},
   "source": [
    "<p>The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.</p>\n",
    "<p>The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters (separation).The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own cluster and poorly matched to neighboring clusters.</p>\n",
    "<p>In machine learning, boosting is an ensemble meta-algorithm for primarily reducing bias, and also variance in supervised learning, and a family of machine learning algorithms that convert weak learners to strong ones.</p>\n",
    "<p>Bagging, also known as Bootstrap aggregating, is an ensemble learning technique that helps to improve the performance and accuracy of machine learning algorithms. It is used to deal with bias-variance trade-offs and reduces the variance of a prediction model.</p>\n",
    "<p>What is eager learner in machine learning?\n",
    "Eager learners construct a classification model based on the given training data before receiving data for classification. It must be able to commit to a single hypothesis that covers the entire instance space. Due to the model construction, eager learners take a long time for train and less time to predict.</p>\n",
    "<p>n machine learning, lazy learning is a learning method in which generalization of the training data is, in theory, delayed until a query is made to the system, as opposed to eager learning, where the system tries to generalize the training data before receiving queries.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293092ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
