{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Is there any way to combine five different models that have all been trained on the same training data and have all achieved 95 percent precision? If so, how can you go about doing it? If not, what is the reason?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification accuracy is the total number of correct predictions divided by the total number of predictions made for a dataset.\n",
    "\n",
    "As a performance measure, accuracy is inappropriate for imbalanced classification problems.\n",
    "\n",
    "The main reason is that the overwhelming number of examples from the majority class (or classes) will overwhelm the number of examples in the minority class, meaning that even unskillful models can achieve accuracy scores of 90 percent, or 99 percent, depending on how severe the class imbalance happens to be.\n",
    "\n",
    "An alternative to using classification accuracy is to use precision and recall metrics.\n",
    "\n",
    "In this tutorial, you will discover how to calculate and develop an intuition for precision and recall for imbalanced classification.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "Precision quantifies the number of positive class predictions that actually belong to the positive class.\n",
    "Recall quantifies the number of positive class predictions made out of all positive examples in the dataset.\n",
    "F-Measure provides a single score that balances both the concerns of precision and recall in one number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. What&#39;s the difference between hard voting classifiers and soft voting classifiers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In hard voting (also known as majority voting), every individual classifier votes for a class, and the majority wins. In statistical terms, the predicted target label of the ensemble is the mode of the distribution of individually predicted labels.\n",
    "In soft voting, every individual classifier provides a probability value that a specific data point belongs to a particular target class. The predictions are weighted by the classifier's importance and summed up. Then the target label with the greatest sum of weighted probabilities wins the vote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Is it possible to distribute a bagging ensemble&#39;s training through several servers to speed up the process? Pasting ensembles, boosting ensembles, Random Forests, and stacking ensembles are all options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "decreasing the learning rate, early stopping to find the right number of predictors (you probably have too many)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. What is the advantage of evaluating out of the bag?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No leakage of data: Since the model is validated on the OOB Sample, which means data hasn’t been used while training the model in any way, so there isn’t any leakage of data and henceforth ensures a better predictive model.<br>\n",
    "Less Variance :  . Since OOB_Score ensures no leakage, so there is no over-fitting of the data and hence least variance.<br>\n",
    "Better Predictive Model: OOB_Score helps in the least variance and hence it makes a much better predictive model than a model using other validation techniques.<br>\n",
    "Less Computation: It requires less computation as it allows one to test the data as it is being trained.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. What distinguishes Extra-Trees from ordinary Random Forests? What good would this extra randomness do? Is it true that Extra-Tree Random Forests are slower or faster than normal Random Forests?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest uses bootstrap replicas, that is to say, it subsamples the input data with replacement, whereas Extra Trees use the whole original sample. In the Extra Trees sklearn implementation there is an optional parameter that allows users to bootstrap replicas, but by default, it uses the entire input sample. This may increase variance because bootstrapping makes it more diversified.\n",
    "Another difference is the selection of cut points in order to split nodes. Random Forest chooses the optimum split while Extra Trees chooses it randomly. However, once the split points are selected, the two algorithms choose the best one between all the subset of features. Therefore, Extra Trees adds randomization but still has optimization.<br>\n",
    "\n",
    "\n",
    "In terms of computational cost, and therefore execution time, the Extra Trees algorithm is faster. This algorithm saves time because the whole procedure is the same, but it randomly chooses the split point and does not calculate the optimal one.\n",
    "\n",
    "From these reasons comes the name of Extra Trees (Extremely Randomized Trees)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Which hyperparameters and how do you tweak if your AdaBoost ensemble underfits the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosting involves creating and adding trees to the model sequentially.\n",
    "\n",
    "New trees are created to correct the residual errors in the predictions from the existing sequence of trees.\n",
    "\n",
    "The effect is that the model can quickly fit, then overfit the training dataset.\n",
    "\n",
    "A technique to slow down the learning in the gradient boosting model is to apply a weighting factor for the corrections by new trees when added to the model.\n",
    "\n",
    "This weighting is called the shrinkage factor or the learning rate, depending on the literature or the tool.\n",
    "\n",
    "Naive gradient boosting is the same as gradient boosting with shrinkage where the shrinkage factor is set to 1.0. Setting values less than 1.0 has the effect of making less corrections for each tree added to the model. This in turn results in more trees that must be added to the model.\n",
    "\n",
    "It is common to have small values in the range of 0.1 to 0.3, as well as values less than 0.1.\n",
    "\n",
    "Let’s investigate the effect of the learning rate on a standard machine learning dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Should you raise or decrease the learning rate if your Gradient Boosting ensemble overfits the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When creating gradient boosting models with XGBoost using the scikit-learn wrapper, the learning_rate parameter can be set to control the weighting of new trees added to the model.\n",
    "\n",
    "We can use the grid search capability in scikit-learn to evaluate the effect on logarithmic loss of training a gradient boosting model with different learning rate values.\n",
    "\n",
    "We will hold the number of trees constant at the default of 100 and evaluate of suite of standard values for the learning rate on the Otto dataset.\n",
    "\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "There are 6 variations of learning rate to be tested and each variation will be evaluated using 10-fold cross validation, meaning that there is a total of 6×10 or 60 XGBoost models to be trained and evaluated.\n",
    "\n",
    "The log loss for each learning rate will be printed as well as the value that resulted in the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
