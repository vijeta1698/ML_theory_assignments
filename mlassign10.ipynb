{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Define the Bayesian interpretation of probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Bayesian interpretation of probability also deals with probability functions defined over single-case variables. But in this case the interpretation is mental rather than physical: probabilities are interpreted as an agent's rational degrees of belief.10 Thus for an agent, P(B = yes) = q if and only if the agent believes that B = yes to degree q and this ascription of degree of belief is rational in the sense outlined below. An agent's degrees of belief are construed as a guide to her actions: she believes B = yes to degree q if and only if she is prepared to place a bet of q S on B = yes, with return S if B = yes turns out to be true. Here S is an unknown stake, which may be positive or negative, and q is called a betting quotient. An agent's belief function is the function that maps an assignment to the agent's degree of belief in that assignment.\n",
    "\n",
    "An agent's betting quotients are called coherent if one cannot choose stakes for her bets that force her to lose money whatever happens. (Such a set of stakes is called a Dutch book.) It is not hard to see that a coherent belief function is a probability function. First q ≥ 0, for otherwise one can set S to be negative and the agent will lose whatever happens: she will lose qS > 0 if the assignment on which she is betting turns out to be false and will lose (q – 1)S > 0 if it turns out to be true. Moreover Συ@V qv = 1 where qv is the betting quotient on assignment N, for otherwise if Σv qv > 1 we can set eacn Sv = S > 0 and the agent will lose (Συ qv − 1)S > 0 (since exactly one of the υ will turn out true), and if Συ qv < 1 we can set each Sv = S < 0 to ensure positive loss.\n",
    "\n",
    "Coherence is taken to be a necessary condition for rationality. For an agent's degrees of belief to be rational they must be coherent, and hence they must be probabilities. Subjective Bayesianism is the view that coherence is also sufficient for rationality, so that an agent's belief function is rational if and only if it is a probability function. This interpretation of probability is subjective because it depends on the agent as to whether P(v) = q. Different agents can choose different probabilities for v and their belief functions will be equally rational. Objective Bayesianism, discussed in detail in Part III, imposes further rationality constraints on degrees of belief — not just coherence. Very often objective Bayesianism constrains degree of belief in such a way that only one value for P(v) is deemed rational on the basis of an agent's evidence. Thus, objective Bayesian probability varies as evidence varies but two agents with the same evidence often adopt the same probabilities as their rational degrees of belief.11\n",
    "\n",
    "Many subjective Bayesians claim that an agent should update her degrees of belief by Bayesian conditionalisation: her new degrees of belief should be her old degrees of belief conditional on new evidence, Pt+1(v) = Pt(v|u) where u represents the evidence that the agent has learned between time t and time t + 1. In cases where Pt(v|u) is harder to quantify than Pt(u|v) and Pt(v) this conditional probability may be calculated using Bayes’ theorem: P(v|u) = P(u|v)P(v)|P(u), which holds for any probability function P. Note that Bayesian conditionalisation is more appropriate as a constraint on subjective Bayesian updating than on objective Bayesian updating, because it disagrees with the usual principles of objective Bayesianism ([Williamson, 2008b]). ‘Bayesianism’ is variously used to refer to the Bayesian interpretation of probability, the endorsement of Bayesian conditionalisation or the use of Bayes’ theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Define probability of a union of two events with equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The general probability addition rule for the union of two events states that P(A∪B)=P(A)+P(B)−P(A∩B) P ( A ∪ B ) = P ( A ) + P ( B ) − P ( A ∩ B ) , where A∩B A ∩ B is the intersection of the two sets. The addition rule can be shortened if the sets are disjoint: P(A∪B)=P(A)+P(B) P ( A ∪ B ) = P ( A ) + P ( B ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. What is joint probability? What is its formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability is a branch of mathematics which deals with the occurrence of a random event. In simple words it is the likelihood of a certain event. A statistical measure that calculates the likelihood of two events occurring together and at the same point in time is called Joint probability.\n",
    "\n",
    "Let A and B be the two events, joint probability is the probability of event B occurring at the same time that event A occurs.\n",
    "\n",
    "Formula for Joint Probability\n",
    "Notation to represent the joint probability can take a few different forms. The following formula represents the joint probability of events with intersection.\n",
    "\n",
    "P (A⋂B)\n",
    "\n",
    "where,\n",
    "\n",
    "A, B= Two events\n",
    "\n",
    "P(A and B),P(AB)=The joint probability of A and B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. What is chain rule of probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(x,y|z)=p(x,y,z)p(z)=p(x|y,z)p(y,z)p(z)=p(x|y,z)p(y|z)\n",
    "\n",
    "On the first step we use the definition of conditional probability. On the second step we use the same definition on the numerator to convert the joint probability p(x,y,z) into a conditional p(x|y,z) and a joint p(y,z). Finally, we divide p(y,z) by p(z) applying once again the definition of conditional probability, and we obtain the result.\n",
    "\n",
    "Another way of looking at it is that you can just ignore variables that are always on the right side of the conditional sign. In that case the expression is just the usual conditional probability:\n",
    "\n",
    "p(x,y)=p(x|y)p(y)\n",
    "\n",
    "You simply condition all of these probabilities on z and you get your original formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. What is conditional probability means? What is the formula of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conditional probability refers to the chances that some outcome occurs given that another event has also occurred.\n",
    "It is often stated as the probability of B given A and is written as P(B|A), where the probability of B depends on that of A happening.\n",
    "Conditional probability can be contrasted with unconditional probability.\n",
    "Probabilities are classified as either conditional, marginal, or joint.\n",
    "Bayes' theorem is a mathematical formula used in calculating conditional probability.\n",
    "\n",
    "Conditional Probability Formula\n",
    "P(B|A) = P(A and B) / P(A)\n",
    "Or:\n",
    "\n",
    "P(B|A) = P(A∩B) / P(A)\n",
    "Where\n",
    "P = Probability\n",
    "A = Event A\n",
    "B = Event B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. What are continuous random variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if an experiment can result in an infinite, non-countable\n",
    "number of outcomes, then the random variable defined can be\n",
    "“continuous”.\n",
    "Whenever the value of a random variable is measured rather\n",
    "than counted, a continuous random variable is defined.\n",
    "\t Water level in the reservoir\n",
    "\t Distance between two points\n",
    "\t Amount of peanut butter in a jar\n",
    "\t Level of gasoline in fuel tank of a car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. What are Bernoulli distributions? What is the formula of it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernoulli Distribution is a type of discrete probability distribution where every experiment conducted asks a question that can be answered only in yes or no. In other words, the random variable can be 1 with a probability p or it can be 0 with a probability (1 - p). Such an experiment is called a Bernoulli trial. A pass or fail exam can be modeled by a Bernoulli Distribution.\n",
    "\n",
    "If we have a Binomial Distribution where n = 1 then it becomes a Bernoulli Distribution. As this distribution is very easy to understand, it is used as a basis for deriving more complex distributions. Bernoulli Distribution can be used to describe events that can only have two outcomes, that is, success or failure. In this article, we will learn about the formula, pmf, CDF, and other aspects of the Bernoulli Distribution.\n",
    "\n",
    "Bernoulli Distribution Definition\n",
    "A discrete probability distribution wherein the random variable can only have 2 possible outcomes is known as a Bernoulli Distribution. If in a Bernoulli trial the random variable takes on the value of 1, it means that this is a success. The probability of success is given by p. Similarly, if the value of the random variable is 0, it indicates failure. The probability of failure is q or 1 - p. Bernoulli distribution can be used to derive a binomial distribution, geometric distribution, and negative binomial distribution.\n",
    "\n",
    "<b>Bernoulli Distribution Example</b>\n",
    "Suppose there is an experiment where you flip a coin that is fair. If the outcome of the flip is heads then you will win. This means that the probability of getting heads is p = 1/2. If X is the random variable following a Bernoulli Distribution, we get P(X = 1) = p = 1/2.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<b>Bernoulli Distribution Formula</b>\n",
    "A binomial random variable, X, is also known as an indicator variable. This is because if an event results in success then X = 1 and if the outcome is a failure then X = 0. X can be written as X \n",
    "∼\n",
    " Bernoulli (p), where p is the parameter. The formulas for Bernoulli distribution are given by the probability mass function (pmf) and the cumulative distribution function (CDF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. What is binomial distribution? What is the formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binomial distribution is a commonly used discrete distribution in statistics. The normal distribution as opposed to a binomial distribution is a continuous distribution. The binomial distribution represents the probability for 'x' successes of an experiment in 'n' trials, given a success probability 'p' for each trial at the experiment.\n",
    "\n",
    "Binomial Distribution in Statistics: The binomial distribution forms the base for the famous binomial test of statistical importance. A test that has a single outcome such as success/failure is also called a Bernoulli trial or Bernoulli experiment, and a series of outcomes is called a Bernoulli process. Consider an experiment where each time a question is asked for a yes/no with a series of n experiments. Then in the binomial probability distribution, the boolean-valued outcome the success/yes/true/one is represented with probability p and the failure/no/false/zero with probability q (q = 1 − p). In a single experiment when n = 1, the binomial distribution is called a Bernoulli distribution.\n",
    "    \n",
    "    The binomial distribution formula is for any random variable X, given by;  P(x:n,p) = nC\n",
    "x\n",
    " px (1-p)n-x Or P(x:n,p) = nCx px (q)n-x\n",
    "\n",
    "where,\n",
    "\n",
    "n = the number of experiments\n",
    "x = 0, 1, 2, 3, 4, …\n",
    "p = Probability of success in a single experiment\n",
    "q = Probability of failure in a single experiment (= 1 – p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. What is Poisson distribution? What is the formula?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Poisson distribution is a discrete probability function that means the variable can only take specific values in a given list of numbers, probably infinite. A Poisson distribution measures how many times an event is likely to occur within “x” period of time. In other words, we can define it as the probability distribution that results from the Poisson experiment. A Poisson experiment is a statistical experiment that classifies the experiment into two categories, such as success or failure. Poisson distribution is a limiting process of the binomial distribution.\n",
    "\n",
    "A Poisson random variable “x” defines the number of successes in the experiment. This distribution occurs when there are events that do not occur as the outcomes of a definite number of outcomes. Poisson distribution is used under certain conditions. They are:\n",
    "\n",
    "The number of trials “n” tends to infinity\n",
    "Probability of success “p” tends to zero\n",
    "np = 1 is finite\n",
    "\n",
    "The formula for the Poisson distribution function is given by:\n",
    "\n",
    "f(x) =(e– λ λx)/x!\n",
    "\n",
    "Where,\n",
    "\n",
    "e is the base of the logarithm\n",
    "\n",
    "x is a Poisson random variable\n",
    "\n",
    "λ is an average rate of value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. Define covariance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In mathematics and statistics, covariance is a measure of the relationship between two random variables. The metric evaluates how much – to what extent – the variables change together. In other words, it is essentially a measure of the variance between two variables. However, the metric does not assess the dependency between variables.\n",
    "Unlike the correlation coefficient, covariance is measured in units. The units are computed by multiplying the units of the two variables. The variance can take any positive or negative values. The values are interpreted as follows:\n",
    "\n",
    "Positive covariance: Indicates that two variables tend to move in the same direction.\n",
    "Negative covariance: Reveals that two variables tend to move in inverse directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. Define correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation is a statistical measure that expresses the extent to which two variables are linearly related (meaning they change together at a constant rate). It's a common tool for describing simple relationships without making a statement about cause and effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12. Define sampling with replacement. Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling without Replacement is a way to figure out probability without replacement. In other words, you don’t replace the first item you choose before you choose a second. This dramatically changes the odds of choosing sample items. Taking the above example, you would have the same list of names to choose two people from. And your list of results would similar, except you couldn’t choose the same person twice:\n",
    "\n",
    "John, Jack\n",
    "John, Qui\n",
    "Jack, Qui\n",
    "Jack Tina…\n",
    "But now, your two items are dependent, or linked to each other. When you choose the first item, you have a 1/7 probability of picking a name. But then, assuming you don’t replace the name, you only have six names to pick from. That gives you a 1/6 chance of choosing a second name. The odds become:\n",
    "\n",
    "P(John, Jack) = (1/7) * (1/6) = .024.\n",
    "P(John, Qui) = (1/7) * (1/6) = .024.\n",
    "P(Jack, Qui) = (1/7) * (1/6) = .024.\n",
    "P(Jack Tina) = (1/7) * (1/6) = .024…\n",
    "As you can probably figure out, I’ve only used a few items here, so the odds only change a little. But larger samples taken from small populations can have more dramatic results.\n",
    "\n",
    "You can tell how dramatic these results are by calculating the covariance. That’s a measure of how much probabilities of two items are linked together; the higher the covariance, the more dramatic the results. A covariance of zero would mean there’s no difference between sampling with replacement or sampling without.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13. What is sampling without replacement? Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a population of potato sacks, each of which has either 12, 13, 14, 15, 16, 17, or 18 potatoes, and all the values are equally likely. Suppose that, in this population, there is exactly one sack with each number. So the whole population has seven sacks. If I sample two with replacement, then I first pick one (say 14). I had a 1/7 probability of choosing that one. Then I replace it. Then I pick another. Every one of them still has 1/7 probability of being chosen. And there are exactly 49 different possibilities here (assuming we distinguish between the first and second.) They are: (12,12), (12,13), (12, 14), (12,15), (12,16), (12,17), (12,18), (13,12), (13,13), (13,14), etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14. What is hypothesis? Give example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hypothesis is a potential explanation for something that happens or that you observe and think to be true. It can also be used to determine the relationship between two or more variables that you think might be related to each other.\n",
    "\n",
    "Hypotheses are usually written as if/then statements, such as if someone eats a lot of sugar, then they will develop cavities in their teeth. These statements identify specific variables (in this case, eating a large amount of sugar) and propose a result (in this case, teeth developing cavities).\n",
    "\n",
    "When creating a hypothesis, it's best to make it as strong as possible before conducting experiments or making further observations. This can be achieved by asking questions, brainstorming, being specific in the language you use, being logical and making sure the hypothesis is testable within constraints.\n",
    "\n",
    "If an office provides snacks, employees will take fewer off-site breaks: This is a simple hypothesis, as the independent variable is providing snacks at the office and the dependent variable is whether fewer employees choose to take an off-site break.\n",
    "If the company has a holiday party and everyone in the office attends, then morale will rise and as a result, so will productivity: This is an example of a complex hypothesis, as a high number of variables would be involved in its testing, such as whether the company has a holiday party, how many employees attend, whether attendees experience a rise in morale and how company productivity is later affected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
