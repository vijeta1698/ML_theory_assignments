{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. What does one mean by the term \"machine learning\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning is the science (and art) of programming computers so they can learn from data.\n",
    "Machine Learning is the field of study that gives computers the ability to learn without being explicitly programmed.\n",
    "\n",
    "A computer program is said to learn from experience E with respect to some task T\n",
    "and some performance measure P, if its performance on T, as measured by P, improves\n",
    "with experience E.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Can you think of 4 distinct types of issues where it shines?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider how you would write a spam filter using traditional programming techni‐\n",
    "ques\n",
    "<center>1. First you would look at what spam typically looks like. You might notice that\n",
    "some words or phrases (such as “4U,” “credit card,” “free,” and “amazing”) tend to\n",
    "come up a lot in the subject. Perhaps you would also notice a few other patterns\n",
    "in the sender’s name, the email’s body, and so on.<br>\n",
    "2. You would write a detection algorithm for each of the patterns that you noticed,\n",
    "and your program would flag emails as spam if a number of these patterns are\n",
    "detected.<br>\n",
    "3. You would test your program, and repeat steps 1 and 2 until it is good enough.<center>\n",
    "<br>\n",
    "Since the problem is not trivial, your program will likely become a long list of com‐\n",
    "plex rules—pretty hard to maintain.\n",
    "In contrast, a spam filter based on Machine Learning techniques automatically learns\n",
    "which words and phrases are good predictors of spam by detecting unusually fre‐\n",
    "quent patterns of words in the spam examples compared to the ham examples\n",
    "The program is much shorter, easier to maintain, and most likely more\n",
    "accurate.<br><br>\n",
    "<br>\n",
    "Another area where Machine Learning shines is for problems that either are too complex for traditional approaches or have no known algorithm. For example, consider speech recognition: say you want to start simple and write a program capable of distinguishing the words “one” and “two.” You might notice that the word “two” starts with a high-pitch sound (“T”), so you could hardcode an algorithm that measures\n",
    "high-pitch sound intensity and use that to distinguish ones and twos. Obviously this technique will not scale to thousands of words spoken by millions of very different people in noisy environments and in dozens of languages. The best solution (at least\n",
    "today) is to write an algorithm that learns by itself, given many example recordings for each word.\n",
    "<br>\n",
    "Problems for which existing solutions require a lot of hand-tuning or long lists of\n",
    "rules: one Machine Learning algorithm can often simplify code and perform better.<br><br>\n",
    "• Complex problems for which there is no good solution at all using a traditional approach: the best Machine Learning techniques can find a solution.<br>\n",
    "• Fluctuating environments: a Machine Learning system can adapt to new data.<br>\n",
    "• Getting insights about complex problems and large amounts of data.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.What is a labeled training set, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeled data is a designation for pieces of data that have been tagged with one or more labels identifying certain properties or characteristics, or classifications or contained objects. Labels make that data specifically useful in certain types of machine learning known as supervised machine learning setups.<br>\n",
    "In supervised learning, the training data you feed to the algorithm includes the desired solutions, called labels<br>\n",
    "for exqample in a spam classification the training set consistes of mails with labels like spam or ham. The machine then lerans from such data and automatically classifies mails as spam or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.What are the two most important tasks that are supervised?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two most common supervised learning tasks are regression and classification. In a regression problem we our prediciton is a scalar value. When we're trying to solve a classification problem, our output is either 1 or 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.Can you think of four examples of unsupervised tasks?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common unsupervised tasks include clustering, visualization, dimensionality reduction and association rule learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.State the machine learning model that would be best to make a robot walk through various unfamiliar terrains?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use a reinforcement learning approach. Reinforcement learning is a system where an \"agent\" observes the environment, selects and performs actions, then recieves a reward or punishment based on the result of the action. Over time the agent learns by itself what is the most productive strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7.Which algorithm will you use to divide your customers into different groups?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would use some sort of clustering algorithm that can find the decision boundaries in the groups automatically. This is an unsupervised approach. However, if I already knew the categories of my customers, then I would choose a supervised approach and go with a classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8.Will you consider the problem of spam detection to be a supervised or unsupervised learning problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would frame it as a supervised learning problem because humans have a general idea about what spam is and what it isn't. We can use this notion to create a labeled dataset for an algorithm to learn from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9.What is the concept of an online learning system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An online learning system learns from new data on-the-fly. As a result, the system is trained incrementally either by using one example at a time or using a mini-batch approach. This keeps each learning step cheap and memory efficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10.What is out-of-core learning, and how does it differ from core learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out-of-core learning is used when a dataset is too large to fit into a computer's memory. The algorithm loads part of the data, runs a training step, then repeats the process until it has run on all the data.4\n",
    "<br>\n",
    "\n",
    "\n",
    "in-core means the solver can hold the entire matrix in RAM for solving.\n",
    "\n",
    "out-of-core means the solver cannot hold the entire matrix in RAM for solving. Instead it does the solving on smaller parts of the matrix in RAM by writing the entire matrix to disk storage. That means it spends time reading and writing a lot of data to the disk to make its way through the entire matrix. This takes more time to solve.\n",
    "Share on Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11.What kind of learning algorithm makes predictions using a similarity measure?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance-based learning algorithms use a measure of similarity to generalize to new cases. In an instance-based learning system, the algorithm learns the examples by heart, then uses the similarity measure to generalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12.What's the difference between a model parameter and a hyperparameter in a learning algorithm?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A hyperparameter is a parameter of the learning algorithm, not the model. For example, in a simple linear regression problem our model is parameterized by theta which is a vector of weights. In order to find the best values for theta we have a cost function which is run repeatedly by the gradient descent algorithm. Gradient descent has a hyperparameter called alpha which is the learning rate of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#13.What are the criteria that model-based learning algorithms look for? What is the most popular method they use to achieve success? What method do they use to make predictions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for a model-based algorithm is to be able to generalize to new examples. To do this, model based algorithms search for optimal values for the model's parameters, often called theta. This searching, or \"learning\", is what machine learning is all about. Model-based system learn by minimizing a cost function that measures how bad the system is at making predicitons on new data, plus a penalty for model complexity if the model is regularized. To make a prediction, a new instance's features are fed into a hypothesis function which uses the minimized theta found by repeatedly running the cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#14.Can you name four of the most important Machine Learning challenges?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "    Not gathering enough data, or sampling noise. Sampling noise means we'll have non-representative data as a result of chance.\n",
    "\n",
    "    Using a dataset that is not representative of the cases you want to generalize to. This is called sampling bias. For example, if you want to train an algorithm with \"cat videos\", and all your videos are from YouTube, you're actually training an algorithm to learn about \"YouTube cat videos.\"\n",
    "\n",
    "    Your dataset is full of missing values, outliers, and noise (poor measurments).\n",
    "\n",
    "    The features in your dataset are irrelevant. Garbage in, garbage out.\n",
    "        Feature selection - choose the most relevant features from your dataset\n",
    "        Feature extraction - combine features in your dataset to generate a new, more useful feature\n",
    "\n",
    "    When your model performs well on the training data, but not on test data, you've over fit your model. Models that suffer from overfitting do not generalize well to new examples. Overfitting happens when the model is too complex relative to the amount and noisiness of the data.\n",
    "        Try simplyfying the model by reducing the number of features in the data or constraining the parameters by reducing the degrees of freedom.\n",
    "        Gather more training data.\n",
    "        Reduce noise in the training data by fixing errors and removing outliers.\n",
    "\n",
    "    When your model is too simple to learn the underlying structure of the data you've underfit your model.\n",
    "        Select a more powerful model with more parameters\n",
    "        Use feature engineering to feed better features to the model\n",
    "        Reduce the constraints of the model (increase degrees of freedom, reduce regularization parameter, etc.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#15.What happens if the model performs well on the training data but fails to generalize the results to new situations? Can you think of three different options?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a case where the model is overfitting the training data. To couteract overfitting, we can reduce the complexity of the model by removing features or constraining the parameters. We could gather more data. Finally we can reduce noisiness in the data by fixing errors and removing outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#16.What exactly is a test set, and why would you need one?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we want to know how well our model generalizes to new cases we prefer to use a test set instead of actually deploying the system. To build the test set we split the training data (50-50, 60-40, 80-20 are common splits) into a training set and test set. Our model is training with the training set. Then we use the model to run predictions on the test set. Our error rate on the test set is called the generalization error or out-of-sample error. This error tells us how well our model performs on examples it has never seen before.\n",
    "\n",
    "If the training error is low, but the generalization error is high, it means we're overfitting our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#17.What is a validation set's purpose?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we have a linear model and we want to perform some hyperparameter tuning to reduce the generalization error. One way to do this 100 different models with 100 different hyperparameter values using the training set and finding the generalization error with the test set. You find the best hyperparameter value gives you 5% generalization error.\n",
    "\n",
    "So you launch the model into production and find you're seeing 15% generalization error. This isn't going as expected. What happened?\n",
    "\n",
    "The problem is that for each iteration of hyperparameter tuning, you measured the generalization error then updated the model using the same test set. In other words, your produced the best generalization error for the test set. The test set no longer represents cases the model hasn't seen before.\n",
    "\n",
    "A common solution to this problem is to have a second holdout set called the validation set. You train multiple models with various hyperparameters using the training set, you select the model and hyperparameters that perform best on the validation set, and when you are happy about your model you run a single final test against the test set to get an estimate of the generalization error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#19.What could go wrong if you use the test set to tune hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our model will not be generalizable to new examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18.What precisely is the train-dev kit, when will you need it, how do you put it to use?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Data Learning algorithm like gradient descent use training data iteratively to learn the parameters of the model.\n",
    "\n",
    "In the training process, data is slowly memorized into the parametric aspect of the model with the goal of generalizing this model to unseen data.\n",
    "\n",
    "Training process emits the parameters of a model and hence the sole purpose of training data is to make a decision about which parameters to pick given huge options to choose from.\n",
    "\n",
    "Training Data Learning algorithm like gradient descent use training data iteratively to learn the parameters of the model.\n",
    "\n",
    "In the training process, data is slowly memorized into the parametric aspect of the model with the goal of generalizing this model to unseen data.\n",
    "\n",
    "Training process emits the parameters of a model and hence the sole purpose of training data is to make a decision about which parameters to pick given huge options to choose from.\n",
    "\n",
    "So when you have successfully consumed train and dev set while building a machine learning system you are left with the final best model out of all the ideas you tried.\n",
    "\n",
    "We use test-set as a proxy for unseen data and evaluate our model on test-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
